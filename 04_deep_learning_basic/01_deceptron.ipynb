{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66beeda3",
   "metadata": {},
   "source": [
    "## 인공신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8778adf8",
   "metadata": {},
   "source": [
    "1. **매컬리-피츠 뉴런(McCulloch-Pitts Neuron)**\n",
    "\n",
    "    1943년, 신경과학자 워런 매컬리(Warren McCulloch)와 논리학자 월터 피츠(Walter Pitts)는 뉴런을 수학적으로 모델링하여 단순 논리 연산을 수행할 수 있게 했다.\n",
    "\n",
    "    이 모델은 뉴런이 \"발화\"하거나 \"비발화\"하는 이진 결정 방식으로 동작했고, 학습 능력에는 한계가 있었다. 현재 인공신경망의 노드 개념의 기초가 되었다.\n",
    "\n",
    "2. **단층 퍼셉트론(Single-layer Perceptron)**\n",
    "\n",
    "    로젠블럿의 퍼셉트론은 매컬리-피츠 뉴런을 확장하여 가중치를 통해 데이터를 학습할 수 있게 했고, 선형 분류 문제(예: OR 또는 AND 문제)에서는 성공적인 성능을 보였다.\n",
    "\n",
    "    그러나 XOR 문제와 같은 비선형 문제를 해결하지 못한다는 한계가 있었다.\n",
    "\n",
    "    이러한 단점으로 인해 인공신경망 연구는 1970년대에 한동안 침체기에 들어갔는데, 이를 **첫번째 AI 겨울(AI Winter)** 이라 부른다.\n",
    "\n",
    "3. **다층 퍼셉트론(Multilayer Perceptron, MLP)**\n",
    "\n",
    "    1980년대, 입력층과 출력층 사이에 **은닉층(hidden layer)** 을 추가하여 비선형 문제도 해결할 수 있는 구조의 MLP가 등장해 다시 주목받기 시작한다.\n",
    "\n",
    "    은닉층을 여러 개 쌓은 MLP는 오차 역전파(Backpropagation) 알고리즘을 통해 각 층의 가중치를 조정하며 학습할 수 있다.\n",
    "\n",
    "    이 방법은 제프리 힌튼(Geoffrey Hinton)과 데이비드 럼멜하트(David Rumelhart)에 의해 개발되었으며, MLP의 성능을 비약적으로 향상시켰다.\n",
    "\n",
    "4. **심층 신경망(Deep Neural Network)**\n",
    "\n",
    "    다층 퍼셉트론의 등장 이후 인공신경망 연구는 빠르게 발전하여 오늘날의 심층 신경망(Deep Neural Network) 개념으로 이어졌다.\n",
    "\n",
    "    이처럼 매컬리-피츠 뉴런에서 시작된 인공신경망 연구는 퍼셉트론을 거쳐 다층 퍼셉트론으로 발전했으며, 현대의 다양한 인공지능 응용 분야에 널리 활용되고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1bfb9d",
   "metadata": {},
   "source": [
    "## Perceptron\n",
    "퍼셉트론(Perceptron)은 인공지능과 머신러닝의 기본 모델 중 하나로, 인공 신경망의 가장 기본 단위이다.\n",
    "\n",
    "1958년 프랭크 로젠블랫(Frank Rosenblatt)에 의해 개발되었으며, 주로 이진 분류 문제를 해결하는 데 사용한다.\n",
    "\n",
    "**퍼셉트론의 구성 요소**\n",
    "1. **입력 노드(Input Nodes)**: 퍼셉트론은 여러 개의 입력을 받으며, 각 입력은 특징 벡터의 한 요소에 해당한다.\n",
    "2. **가중치(Weights)**: 각 입력에는 가중치가 부여된다. 가중치는 학습 과정에서 조정되며, 입력이 결과에 미치는 영향을 조절하는 역할을 한다.\n",
    "3. **편향(Bias)**: 퍼셉트론의 활성화 함수를 조절하는 상수 값이다. 입력 데이터의 선형 조합이 특정 값 이상이 되도록 하는 역할을 한다.\n",
    "4. **활성화 함수(Activation Function)**: 입력 값과 가중치의 선형 결합 결과를 이진 출력으로 변환한다. 퍼셉트론에서는 보통 단위 계단 함수를 사용한다.\n",
    "\n",
    "**퍼셉트론의 작동 원리**\n",
    "\n",
    "1. **입력 신호와 가중치의 합산:**\n",
    "\n",
    "   $\n",
    "   z = \\sum_{i=1}^{n} w_i x_i + b\n",
    "   $\n",
    "\n",
    "   여기서:\n",
    "   - $ x_i $는 $ i $번째 입력 값,\n",
    "   - $ w_i $는 $ i $번째 가중치,\n",
    "   - $ b $는 편향(bias) 값,\n",
    "   - $ z $는 가중치가 적용된 입력 신호의 총합이다.\n",
    "\n",
    "2. **활성화 함수 적용:**\n",
    "\n",
    "   $\n",
    "   y = \\begin{cases}\n",
    "      1, & \\text{if } z \\geq 0 \\\\\n",
    "      0, & \\text{if } z < 0\n",
    "   \\end{cases}\n",
    "   $\n",
    "\n",
    "   여기서:\n",
    "   - $ y $는 퍼셉트론의 출력 값으로, 활성화 함수에 의해 결정된다.\n",
    "   - 활성화 함수는 대표적으로 **계단 함수**(step function)로, 총합 $ z $가 0 이상일 때 1을, 그렇지 않으면 0을 출력한다.\n",
    "\n",
    "    ![](https://d.pr/i/lt1GXE+)\n",
    "\n",
    "이 수식을 통해 퍼셉트론은 입력을 받아 단순한 이진 분류를 수행한다.\n",
    "\n",
    "**퍼셉트론의 한계**\n",
    "\n",
    "퍼셉트론은 단층 구조로 구성되어 있기 때문에 선형 분리가 가능한 문제만 해결할 수 있다.\n",
    "\n",
    "XOR 문제와 같이 선형 분리가 불가능한 문제는 단일 퍼셉트론으로 해결할 수 없다.\n",
    "\n",
    "이러한 한계를 이유로 AI의 첫번째 겨울을 맞이하였으며, 이후 1980년대에 오차역전파와 다층 퍼셉트론(MLP: Multi-Layer Perceptron)에 의해 이 한계가 극복되었다.\n",
    "\n",
    "**선형 분리**\n",
    "![](https://d.pr/i/uLz908+)\n",
    "\n",
    "**논리 게이트(Logical Gates)**\n",
    "1. AND (논리곱)\n",
    "    - **정의**: 두 입력이 모두 1일 때만 1을 출력하고, 나머지 경우에는 0을 출력.\n",
    "    - **진리표**:\n",
    "\n",
    "      | 입력 A | 입력 B | AND |\n",
    "      |--------|--------|-----|\n",
    "      | 0      | 0      | 0   |\n",
    "      | 0      | 1      | 0   |\n",
    "      | 1      | 0      | 0   |\n",
    "      | 1      | 1      | 1   |\n",
    "\n",
    "2. OR (논리합)\n",
    "    - **정의**: 두 입력 중 하나라도 1이면 1을 출력하고, 둘 다 0일 때만 0을 출력.\n",
    "    - **진리표**:\n",
    "\n",
    "      | 입력 A | 입력 B | OR  |\n",
    "      |--------|--------|-----|\n",
    "      | 0      | 0      | 0   |\n",
    "      | 0      | 1      | 1   |\n",
    "      | 1      | 0      | 1   |\n",
    "      | 1      | 1      | 1   |\n",
    "\n",
    "3. XOR (배타적 논리합)\n",
    "    - **정의**: 두 입력이 다를 때만 1을 출력하고, 같을 때는 0을 출력.\n",
    "    - **진리표**:\n",
    "\n",
    "      | 입력 A | 입력 B | XOR |\n",
    "      |--------|--------|-----|\n",
    "      | 0      | 0      | 0   |\n",
    "      | 0      | 1      | 1   |\n",
    "      | 1      | 0      | 1   |\n",
    "      | 1      | 1      | 0   |\n",
    "\n",
    "4. NAND (부정 논리곱)\n",
    "    - **정의**: AND의 결과를 뒤집어, 두 입력이 모두 1일 때만 0을 출력하고, 나머지 경우에는 1을 출력.\n",
    "    - **진리표**:\n",
    "\n",
    "      | 입력 A | 입력 B | NAND |\n",
    "      |--------|--------|------|\n",
    "      | 0      | 0      | 1    |\n",
    "      | 0      | 1      | 1    |\n",
    "      | 1      | 0      | 1    |\n",
    "      | 1      | 1      | 0    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7eeaa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "981e1b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "    \n",
    "    def activate(self, x):\n",
    "        return 1 if np.dot(self.weights, x) + self.bias > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aacb933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: (0, 0) | output: 0\n",
      "input: (0, 1) | output: 0\n",
      "input: (1, 0) | output: 0\n",
      "input: (1, 1) | output: 1\n"
     ]
    }
   ],
   "source": [
    "test_case = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "\n",
    "AND_gate = Perceptron(weights=[0.5, 0.5], bias=-0.7)\n",
    "\n",
    "for test in test_case:\n",
    "    print(f'input: {test} | output: {AND_gate.activate(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12c2a211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: (0, 0) | output: 0\n",
      "input: (0, 1) | output: 0\n",
      "input: (1, 0) | output: 0\n",
      "input: (1, 1) | output: 0\n"
     ]
    }
   ],
   "source": [
    "NAND_gate = Perceptron(weights=[-0.5, -0.5], bias=-0.7)\n",
    "\n",
    "for test in test_case:\n",
    "    print(f'input: {test} | output: {NAND_gate.activate(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65438cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## XOR gate\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], ])\n",
    "y = np.array([])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5061cc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다층 퍼셉트론 (multi-layer perceptron, MLP)\n",
    "def XOR_gate(x1, x2):\n",
    "    or_out = OR_gate.activate([x1, x2])\n",
    "    nand_out = NAND_gate.activate([x1, x2])\n",
    "    return AND_gate.activate([or_out, nand_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7903f064",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in test_case:\n",
    "    print(f'input {test} | output: {XOR_gate(test[0], test[1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3993a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([0, 1, 1, 0])\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(4, 4),  # 은닉층 크기\n",
    "    activation='relu',          # 활성화 함수\n",
    "    solver='adam',              # 가중치 업데이트 방식\n",
    "    max_iter=1000,              # 모델의 학습 반복 횟수 (epoch)\n",
    "    random_state=42             # 가중치 초기화 값 고정\n",
    ")\n",
    "\n",
    "mlp.fit(X, y)\n",
    "\n",
    "pred = mlp.predict(X)\n",
    "for i in range(4):\n",
    "    print(f'XPR([X[i][0]S])')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
