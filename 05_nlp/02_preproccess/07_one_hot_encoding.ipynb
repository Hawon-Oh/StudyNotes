{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4fc30bf",
   "metadata": {},
   "source": [
    "# one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "578efe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"\"\"The Little Prince, written by Antoine de Saint-Exupéry, is a poetic tale about a young prince who travels from his home planet to Earth. The story begins with a pilot stranded in the Sahara Desert after his plane crashes. While trying to fix his plane, he meets a mysterious young boy, the Little Prince.\n",
    "\n",
    "The Little Prince comes from a small asteroid called B-612, where he lives alone with a rose that he loves deeply. He recounts his journey to the pilot, describing his visits to several other planets. Each planet is inhabited by a different character, such as a king, a vain man, a drunkard, a businessman, a geographer, and a fox. Through these encounters, the Prince learns valuable lessons about love, responsibility, and the nature of adult behavior.\n",
    "\n",
    "On Earth, the Little Prince meets various creatures, including a fox, who teaches him about relationships and the importance of taming, which means building ties with others. The fox's famous line, \"You become responsible, forever, for what you have tamed,\" resonates with the Prince's feelings for his rose.\n",
    "\n",
    "Ultimately, the Little Prince realizes that the essence of life is often invisible and can only be seen with the heart. After sharing his wisdom with the pilot, he prepares to return to his asteroid and his beloved rose. The story concludes with the pilot reflecting on the lessons learned from the Little Prince and the enduring impact of their friendship.\n",
    "\n",
    "The narrative is a beautifully simple yet profound exploration of love, loss, and the importance of seeing beyond the surface of things.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae7af6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# 문장 토큰\n",
    "sent_tokens = sent_tokenize(raw_text.lower())\n",
    "\n",
    "# 불용어\n",
    "stopword_set = set(stopwords.words('english'))\n",
    "\n",
    "# 사전 (key=단어, value=빈도)\n",
    "vocab = {}\n",
    "\n",
    "# 토큰/정제/정규화\n",
    "preprocessed_sentences = []\n",
    "\n",
    "# 소문자 변환, 토큰화, 불용어, 단어길이 2이하 제거\n",
    "for st in sent_tokens:\n",
    "    temp = ''\n",
    "    for wt in word_tokenize(st):\n",
    "        \n",
    "        if wt not in stopword_set and len(wt) > 2:\n",
    "            if wt in vocab:\n",
    "                vocab[wt] += 1\n",
    "            else:\n",
    "                vocab[wt] = 1\n",
    "\n",
    "            temp += wt + ' '\n",
    "    \n",
    "    preprocessed_sentences.append(temp[:-1])\n",
    "\n",
    "\n",
    "# vocab = sorted(vocab.items(), key=lambda x: x[1], reverse=True)\n",
    "# print(vocab)\n",
    "# print(preprocessed_sentences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6558bac7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a real number, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m tokenizer = Tokenizer(num_words=\u001b[32m15\u001b[39m, oov_token=\u001b[33m'\u001b[39m\u001b[33m<OOV>\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m sequences = tokenizer.texts_to_sequences(preprocessed_sentences)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m pad_seqs = \u001b[43mpad_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxlen\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncating\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpre\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\keras\\src\\utils\\sequence_utils.py:125\u001b[39m, in \u001b[36mpad_sequences\u001b[39m\u001b[34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[39m\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mTruncating type \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtruncating\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m not understood\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# check `trunc` has expected shape\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m trunc = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trunc.shape[\u001b[32m1\u001b[39m:] != sample_shape:\n\u001b[32m    127\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    128\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mShape of sample \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrunc.shape[\u001b[32m1\u001b[39m:]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m of sequence at \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    129\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mposition \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is different from expected shape \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    130\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    131\u001b[39m     )\n",
      "\u001b[31mTypeError\u001b[39m: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=15, oov_token='<OOV>')\n",
    "sequences = tokenizer.texts_to_sequences(preprocessed_sentences)\n",
    "\n",
    "pad_seqs = pad_sequences(sequences, maxlen=10, truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df0b176",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'padded_seqs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m one_hot_encodded = to_categorical(\u001b[43mpadded_seqs\u001b[49m)\n\u001b[32m      4\u001b[39m one_hot_encodded.shape\n",
      "\u001b[31mNameError\u001b[39m: name 'padded_seqs' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "one_hot_encodded = to_categorical(padded_seqs)\n",
    "one_hot_encodded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1514c5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['난 난 은 근 ㅈ매ㅑㅓ ㅁㅈㅇ러 ㅁㅈ어 ㅔ맺 .', '난 은 을 ㅈ먀ㅐㅗ ㅁㅈㅇ, ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc59625c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['난', '난', '근', 'ㅈ', '매', 'ㅑㅓ', 'ㅁㅈㅇ', '러', 'ㅁㅈ', '어', 'ㅔ', '맺다'],\n",
       " ['난', 'ㅈ', '먀', 'ㅐㅗ', 'ㅁㅈㅇ']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "import re\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "ko_stopwords = ['은', '는', '이', '가', '을', '나']\n",
    "\n",
    "preprocessed_texts = []\n",
    "\n",
    "for text in texts:\n",
    "    tokens = okt.morphs(text, stem=True)\n",
    "    tokens = [token for token in tokens if token not in ko_stopwords]\n",
    "    tokens = [token for token in tokens if not re.search(r'[\\s.,;:?]', token)]\n",
    "\n",
    "    preprocessed_texts.append(tokens)\n",
    "\n",
    "preprocessed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9174f4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 2, 5, 3, 6, 7, 4, 8, 9, 10, 11, 12], [2, 3, 13, 14, 4]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시퀀스 처리\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(preprocessed_texts)\n",
    "sequences = tokenizer.texts_to_sequences(preprocessed_texts)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "168c9958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<OOV>': 1,\n",
       " '난': 2,\n",
       " 'ㅈ': 3,\n",
       " 'ㅁㅈㅇ': 4,\n",
       " '근': 5,\n",
       " '매': 6,\n",
       " 'ㅑㅓ': 7,\n",
       " '러': 8,\n",
       " 'ㅁㅈ': 9,\n",
       " '어': 10,\n",
       " 'ㅔ': 11,\n",
       " '맺다': 12,\n",
       " '먀': 13,\n",
       " 'ㅐㅗ': 14}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46443733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 11, 12],\n",
       "       [13, 14,  4]], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 패딩 처리\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "padded_seqs = pad_sequences(sequences, maxlen=3)\n",
    "padded_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d85e6ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 15)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "one_hot_encodded = to_categorical(padded_seqs)\n",
    "one_hot_encodded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f4ff99",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4eaa5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">209</span> (836.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m209\u001b[0m (836.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">209</span> (836.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m209\u001b[0m (836.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "input = layers.Input(shape=(3, 16))\n",
    "x = layers.SimpleRNN(8)(input)\n",
    "output = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = models.Model(inputs=input, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3924af52",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 2\n'y' sizes: 3\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      3\u001b[39m model.compile(loss=\u001b[33m'\u001b[39m\u001b[33mbinary_crossentropy\u001b[39m\u001b[33m'\u001b[39m, optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m, metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      5\u001b[39m labels = np.array([\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mone_hot_encodded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\data_adapter_utils.py:115\u001b[39m, in \u001b[36mcheck_data_cardinality\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    111\u001b[39m     sizes = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\n\u001b[32m    112\u001b[39m         \u001b[38;5;28mstr\u001b[39m(i.shape[\u001b[32m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tree.flatten(single_data)\n\u001b[32m    113\u001b[39m     )\n\u001b[32m    114\u001b[39m     msg += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m sizes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msizes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[31mValueError\u001b[39m: Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 2\n'y' sizes: 3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "labels = np.array([1, 0, 1])\n",
    "\n",
    "model.fit(one_hot_encodded, labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfd6484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ff757b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
